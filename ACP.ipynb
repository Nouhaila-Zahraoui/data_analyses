print("second program to go : PCA")
import numpy as np
%pip install seaborn
import pandas as pd
import seaborn as sb
import matplotlib.pyplot as plt

import numpy as np
 
def PCA(X , num_components):
     
    #Step-1
    X_meaned = X - np.mean(X , axis = 0)
     
    #Step-2
    cov_mat = np.cov(X_meaned , rowvar = False)
     
    #Step-3
    eigen_values , eigen_vectors = np.linalg.eigh(cov_mat)
     
    #Step-4
    sorted_index = np.argsort(eigen_values)[::-1]
    sorted_eigenvalue = eigen_values[sorted_index]
    sorted_eigenvectors = eigen_vectors[:,sorted_index]
     
    #Step-5
    eigenvector_subset = sorted_eigenvectors[:,0:num_components]
     
    #Step-6
    X_reduced = np.dot(eigenvector_subset.transpose() , X_meaned.transpose() ).transpose()
     
    return X_reduced

   
data = pd.read_csv(("iris.csv"), names=['sepal length','sepal width','petal length',
                                        'petal width','target'])
x = data.iloc[:,0:4]
#prepare the target
target = data.iloc[:,4]
 
#Applying it to PCA function
mat_reduced = PCA(x , 2)
#Creating a Pandas DataFrame of reduced Dataset
principal_df = pd.DataFrame(mat_reduced , columns = ['PC1','PC2'])

print(principal_df)
 
#Concat it with target variable to create a complete Dataset
principal_df = pd.concat([principal_df , pd.DataFrame(target)] , axis = 1)
plt.figure(figsize = (6,6))
sb.scatterplot(data = principal_df , x = 'PC1',y = 'PC2' , hue = 'target' , s = 60 , palette= 'icefire')
plt.show()

#C'est un algorithme statistique utilisé pour réduire la dimensionnalité des données en 
#conservant le maximum d'informations
#L'ACP est souvent utilisé en analyse de données pour réduire la complexité des données
#multidimensionnelles en les projetant sur un espace à plus faible dimension, il est aussi 
#utilisé pour la visualisation de données, la classification, la régression, la compression de 
#données et la sélection de variables.
#Il permet de trouver des combinaisons linéaires des variables d'entrée (appelées "composantes
#principales") qui expliquent la variance maximale dans les données d'entrée. Ces composantes 
#principales peuvent ensuite être utilisées pour représenter les données d'entrée dans un 
#espace de dimensions réduites, ce qui facilite l'analyse et la visualisation.
